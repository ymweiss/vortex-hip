# chipStar Runtime Architecture and Execution

**Part 3: Runtime Loading, Kernel Management, and Execution**

This document provides an in-depth analysis of how the chipStar runtime loads SPIR-V binaries, manages kernels, passes arguments, and executes device code.

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [Compiler-Runtime Interface](#compiler-runtime-interface)
3. [Fat Binary Extraction](#fat-binary-extraction)
4. [SPIR-V Binary Registration](#spirv-binary-registration)
5. [Module Compilation and Loading](#module-compilation-and-loading)
6. [Kernel Discovery and Registration](#kernel-discovery-and-registration)
7. [Kernel Argument Passing](#kernel-argument-passing)
8. [Kernel Launch Pipeline](#kernel-launch-pipeline)
9. [Backend-Specific Execution (OpenCL)](#backend-specific-execution-opencl)
10. [Complete Execution Flow Example](#complete-execution-flow-example)

---

## Executive Summary

The chipStar runtime follows a multi-stage process to execute HIP kernels:

1. **Fat Binary Embedding**: Clang embeds SPIR-V in `.hip_fatbin` ELF section
2. **Registration**: Compiler-generated code registers binaries and symbols at program startup
3. **Extraction**: Runtime extracts SPIR-V from fat binary format
4. **Compilation**: OpenCL/Level Zero JIT compiles SPIR-V to native code
5. **Kernel Discovery**: Runtime analyzes SPIR-V metadata to find kernel entry points
6. **Argument Setup**: Type-aware argument marshalling for each kernel parameter
7. **Launch**: Backend-specific command queue submission

**Key Design Decisions**:
- **Lazy Loading**: Modules compiled only when first used
- **JIT Compilation**: SPIR-V compiled to native code at runtime by OpenCL/Level Zero driver
- **Type-Safe Arguments**: SPIR-V metadata drives argument passing
- **Backend Abstraction**: Common interface for OpenCL and Level Zero

---

## Compiler-Runtime Interface

### The Fat Binary Format

Clang generates a **fat binary** containing both host and device code in a single executable. The device code (SPIR-V) is stored in a special ELF section called `.hip_fatbin`.

**Fat Binary Structure**:

```
┌─────────────────────────────────────────────────────────┐
│                    ELF Executable                       │
├─────────────────────────────────────────────────────────┤
│  .text          │ Host x86-64 machine code              │
├─────────────────┼─────────────────────────────────────┤
│  .data          │ Global variables                      │
├─────────────────┼─────────────────────────────────────┤
│  .hip_fatbin    │ ┌────────────────────────────────┐  │
│                 │ │ __ClangOffloadBundleHeader     │  │
│                 │ ├────────────────────────────────┤  │
│                 │ │ Bundle Entry 1: host-x86_64    │  │
│                 │ ├────────────────────────────────┤  │
│                 │ │ Bundle Entry 2: hip-spirv64    │  │
│                 │ │ ┌────────────────────────────┐ │  │
│                 │ │ │ SPIR-V Magic: 0x07230203  │ │  │
│                 │ │ │ SPIR-V Header (5 words)   │ │  │
│                 │ │ │ OpCapability Kernel       │ │  │
│                 │ │ │ OpMemoryModel Physical64  │ │  │
│                 │ │ │ OpEntryPoint ...          │ │  │
│                 │ │ │ Kernel instructions...    │ │  │
│                 │ │ └────────────────────────────┘ │  │
│                 │ └────────────────────────────────┘  │
├─────────────────┼─────────────────────────────────────┤
│  .ctors         │ Initialization functions            │
│                 │ (__hipRegisterFatBinary)            │
└─────────────────────────────────────────────────────────┘
```

### Compiler-Generated Registration Code

When you compile a HIP source file, Clang generates **registration stubs** that are called during program initialization:

```cpp
// User source file: kernel.hip
__global__ void myKernel(float* data, int n) {
    int tid = threadIdx.x + blockIdx.x * blockDim.x;
    if (tid < n) data[tid] *= 2.0f;
}
```

**Clang-generated registration code** (conceptual - actual implementation in LLVM IR):

```cpp
// Generated by Clang (simplified pseudo-code)
namespace __hip_module {
    // Embedded fat binary data
    __attribute__((section(".hip_fatbin")))
    const unsigned char __hip_fatbin_data[] = {
        /* Clang offload bundle magic */
        '__', 'C', 'L', 'A', 'N', 'G', '_', 'O', 'F', 'F', 'L', 'O', 'A', 'D',
        '_', 'B', 'U', 'N', 'D', 'L', 'E', '_', 'M', 'A', 'G', 'I', 'C', '_', '_',

        /* Bundle header */
        0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,  // numBundles = 2

        /* Bundle entry: hip-spirv64 */
        /* ... SPIR-V binary data ... */
    };

    // Registration function (called during program startup)
    __attribute__((constructor))
    void __hip_module_register() {
        // Register the fat binary with the runtime
        void** handle = __hipRegisterFatBinary(&__hip_fatbin_data);

        // Register each kernel function
        __hipRegisterFunction(handle,
                              (void*)&myKernel,           // Host stub pointer
                              "_Z8myKernelPfi",           // Mangled kernel name
                              "_Z8myKernelPfi",           // Device name
                              -1,                         // Line number
                              nullptr,                    // Unused
                              nullptr);                   // Unused
    }

    // Cleanup function (called at program exit)
    __attribute__((destructor))
    void __hip_module_unregister() {
        __hipUnregisterFatBinary(__hip_module_handle);
    }
}

// Host-side kernel stub (called when you write myKernel<<<...>>>(...))
void myKernel(float* data, int n) {
    // This is a stub that forwards to hipLaunchKernel
    // The real implementation is in the SPIR-V binary
}
```

### HIP API Registration Functions

chipStar implements these registration functions:

```cpp
// Pseudo-code from src/SPVRegister.cc
namespace chipstar {

// Called by compiler-generated code to register a fat binary
void** __hipRegisterFatBinary(void* fatBinaryHandle) {
    // Extract SPIR-V from the fat binary (see next section)
    std::string_view spirvModule = extractSPIRVModule(fatBinaryHandle);

    // Register the SPIR-V module
    SPVRegister::Handle handle =
        SPVRegister::get().registerSource(spirvModule);

    return reinterpret_cast<void**>(handle.Module);
}

// Called by compiler to associate a host pointer with a kernel name
void __hipRegisterFunction(void** handle,
                           const void* hostFuncPtr,
                           const char* deviceFuncName,
                           const char* deviceFuncName2,
                           int lineNum,
                           void* unused1,
                           void* unused2) {
    SPVRegister::Handle moduleHandle{handle};
    SPVRegister::get().bindFunction(moduleHandle,
                                    const_cast<void*>(hostFuncPtr),
                                    deviceFuncName);
}

// Called by compiler to associate a host pointer with a global variable
void __hipRegisterVar(void** handle,
                     const void* hostVarPtr,
                     const char* deviceVarName,
                     size_t size,
                     ...) {
    SPVRegister::Handle moduleHandle{handle};
    SPVRegister::get().bindVariable(moduleHandle,
                                    const_cast<void*>(hostVarPtr),
                                    deviceVarName,
                                    size);
}

}  // namespace chipstar
```

---

## Fat Binary Extraction

### Offload Bundle Format

The fat binary uses Clang's **offload bundle format** to package multiple device binaries (e.g., for different architectures) in a single blob.

**Bundle Header Structure** (from `hip/hip_fatbin.h`):

```cpp
#define CLANG_OFFLOAD_BUNDLER_MAGIC "__CLANG_OFFLOAD_BUNDLE__"

struct __ClangOffloadBundleHeader {
  const char magic[sizeof(CLANG_OFFLOAD_BUNDLER_MAGIC) - 1];
  uint64_t numBundles;       // Number of device code entries
  __ClangOffloadBundleDesc desc[];  // Variable-length array
};

struct __ClangOffloadBundleDesc {
  uint64_t offset;           // Offset from header to device binary
  uint64_t size;             // Size of device binary in bytes
  uint64_t tripleSize;       // Length of target triple string
  const char triple[];       // Target triple (e.g., "hip-spirv64")
};
```

### SPIR-V Extraction Implementation

The runtime extracts the SPIR-V module from the fat binary:

```cpp
// tools/spirv-extractor/spirv-extractor.hh lines 134-218
std::string_view extractSPIRVModule(const void *Bundle, std::string &ErrorMsg) {
  // Step 1: Locate the bundle in the ELF file
  auto magicResult = seekToMagic(Bundle);
  if (!magicResult.ptr) {
    ErrorMsg = "Could not find CLANG_OFFLOAD_BUNDLER_MAGIC or SPIR-V magic";
    return std::string_view();
  }

  // Step 2: Check if it's a direct SPIR-V binary (no bundling)
  if (magicResult.type == BinaryType::SPIRV_ONLY) {
    // Read SPIR-V size from the binary structure
    const uint32_t *words = static_cast<const uint32_t *>(magicResult.ptr);
    size_t size = 0;
    size_t pos = 5;  // Start after 5-word header

    // Scan through SPIR-V instructions to find total size
    while (pos < 1000000) {  // Safety limit
      uint16_t wordCount = words[pos] >> 16;  // High 16 bits = instruction length
      if (wordCount == 0) break;
      pos += wordCount;
    }
    size = pos * sizeof(uint32_t);
    return std::string_view(static_cast<const char *>(magicResult.ptr), size);
  }

  // Step 3: Parse offload bundle header
  using HeaderT = __ClangOffloadBundleHeader;
  using EntryT = __ClangOffloadBundleDesc;

  const auto *Header = (const char *)Bundle;
  auto NumBundles = _copyAs<uint64_t>(Header, offsetof(HeaderT, numBundles));

  // Step 4: Iterate through bundle entries looking for "hip-spirv64"
  const char *Desc = Header + offsetof(HeaderT, desc);
  for (size_t i = 0; i < NumBundles; i++) {
    auto Offset = _copyAs<uint64_t>(Desc, offsetof(EntryT, offset));
    auto Size = _copyAs<uint64_t>(Desc, offsetof(EntryT, size));
    auto TripleSize = _copyAs<uint64_t>(Desc, offsetof(EntryT, tripleSize));
    const char *Triple = Desc + offsetof(EntryT, triple);
    std::string_view EntryID(Triple, TripleSize);

    // Check if this is the SPIR-V entry
    std::string_view SPIRVBundleID = "hip-spirv64";
    if (EntryID.substr(0, SPIRVBundleID.size()) == SPIRVBundleID) {
      // Step 5: Verify SPIR-V magic number
      const char *spirvData = Header + Offset;
      uint32_t magic;
      std::memcpy(&magic, spirvData, sizeof(uint32_t));

      if (magic == 0x07230203) {  // SPIR-V magic
        return std::string_view(spirvData, Size);
      }
    }

    // Move to next bundle entry
    Desc = Triple + TripleSize;
  }

  ErrorMsg = "Couldn't find SPIR-V binary in the bundle!";
  return std::string_view();
}
```

### Seeking to .hip_fatbin Section

Before extracting the bundle, the runtime must locate the `.hip_fatbin` ELF section:

```cpp
// tools/spirv-extractor/spirv-extractor.hh lines 34-62
std::pair<const void *, size_t> findHipFatbinSection(const void *data,
                                                     size_t size) {
  const Elf64_Ehdr *ehdr = static_cast<const Elf64_Ehdr *>(data);

  // Verify ELF magic (0x7F 'E' 'L' 'F')
  if (size < sizeof(Elf64_Ehdr) ||
      memcmp(ehdr->e_ident, ELFMAG, SELFMAG) != 0) {
    return {nullptr, 0};
  }

  // Get section header table
  const Elf64_Shdr *shdr = reinterpret_cast<const Elf64_Shdr *>(
      static_cast<const char *>(data) + ehdr->e_shoff);

  // Get section name string table
  const char *strtab =
      static_cast<const char *>(data) + shdr[ehdr->e_shstrndx].sh_offset;

  // Find .hip_fatbin section
  for (size_t i = 0; i < ehdr->e_shnum; i++) {
    const char *name = strtab + shdr[i].sh_name;
    if (strcmp(name, ".hip_fatbin") == 0) {
      return {static_cast<const char *>(data) + shdr[i].sh_offset,
              shdr[i].sh_size};
    }
  }

  return {nullptr, 0};
}
```

---

## SPIR-V Binary Registration

### SPVRegister: The Central Registry

chipStar maintains a global registry mapping host pointers to SPIR-V modules and their contents.

**Key Data Structures** (`src/SPVRegister.hh` and `src/SPVRegister.cc`):

```cpp
// Represents a SPIR-V module with its kernels and variables
struct SPVModule {
    std::string_view OriginalBinary_;        // Raw SPIR-V from fat binary
    std::vector<uint32_t> FinalizedBinary_;  // Preprocessed SPIR-V

    std::vector<SPVFunction> Kernels;        // Kernel functions in this module
    std::vector<SPVVariable> Variables;      // Global device variables

    SPVModuleInfo ModuleInfo_;               // Parsed metadata
    bool HasAbortFlag = false;
};

// Represents a kernel function
struct SPVFunction {
    SPVModule* Parent;      // Owning module
    HostPtr Ptr;           // Host-side function pointer
    std::string Name;      // Mangled kernel name
};

// Represents a global device variable
struct SPVVariable {
    SPVModule* Parent;
    HostPtr Ptr;
    std::string Name;
    size_t Size;
};

// The global registry
class SPVRegister {
    std::unordered_set<std::unique_ptr<SPVModule>> Sources_;
    std::unordered_map<HostPtr, SPVTypeBase*> HostPtrLookup_;
    std::mutex Mtx_;

public:
    static SPVRegister& get();  // Singleton instance

    // Register a SPIR-V module
    Handle registerSource(std::string_view SourceModule);

    // Bind host pointer to kernel/variable name
    void bindFunction(Handle, HostPtr, const char* Name);
    void bindVariable(Handle, HostPtr, const std::string& Name, size_t Size);

    // Retrieve finalized SPIR-V module
    const SPVModule* getSource(HostPtr);
};
```

### Registration Flow

```cpp
// src/SPVRegister.cc lines 47-91
SPVRegister::Handle SPVRegister::registerSource(std::string_view SourceModule) {
    assert(SourceModule.size() && "Source module must be non-empty.");

    LOCK(Mtx_);
    auto Ins = Sources_.emplace(std::make_unique<SPVModule>());
    SPVModule *SrcMod = Ins.first->get();
    SrcMod->OriginalBinary_ = SourceModule;  // Store reference to SPIR-V

    return Handle{reinterpret_cast<void *>(SrcMod)};
}

void SPVRegister::bindFunction(SPVRegister::Handle Handle, HostPtr Ptr,
                               const char *Name) {
    LOCK(Mtx_);
    auto *SrcMod = reinterpret_cast<SPVModule *>(Handle.Module);
    assert(Sources_.count(SrcMod) && "Not a member of the register.");

    std::string FuncName(Name);

    // Handle duplicate registrations (can happen with templates/inline functions)
    if (HostPtrLookup_.count(Ptr)) {
        // Already registered - ignore duplicate
        return;
    }

    // Create SPVFunction entry
    SrcMod->Kernels.emplace_back(SPVFunction{SrcMod, Ptr, std::move(FuncName)});

    // Map host pointer → function
    HostPtrLookup_.emplace(std::make_pair(Ptr, &SrcMod->Kernels.back()));
}
```

### SPIR-V Preprocessing and Analysis

When a module is first accessed, chipStar **finalizes** it by preprocessing and analyzing the SPIR-V:

```cpp
// src/SPVRegister.cc lines 158-210
SPVModule *SPVRegister::getFinalizedSource(SPVModule *SrcMod) {
    logDebug("Finalize module {}", static_cast<void *>(SrcMod));

    // Already finalized? Return immediately
    if (SrcMod->FinalizedBinary_.size())
        return SrcMod;

    std::vector<uint32_t> Binary;

    // Step 1: Preprocess SPIR-V (name demangling, etc.)
    if (!preprocessSPIRV(SrcMod->OriginalBinary_.data(),
                         SrcMod->OriginalBinary_.size(),
                         PreventNameDemangling,
                         Binary)) {
        logError("Failure in SPIR-V preprocessing.");
        CHIPERR_LOG_AND_THROW("SPIR-V preprocessing failure.", hipErrorTbd);
    }

    // Step 2: Analyze SPIR-V to extract metadata
    if (!analyzeSPIRV(Binary.data(), Binary.size(), SrcMod->ModuleInfo_)) {
        logError("Failure in SPIR-V analysis.");
        CHIPERR_LOG_AND_THROW("SPIR-V analysis failure.", hipErrorTbd);
    }

    // Step 3: Strip chipStar-specific metadata decorations
    if (!postprocessSPIRV(Binary)) {
        logError("Failure in SPIR-V postprocessing.");
        CHIPERR_LOG_AND_THROW("SPIR-V postprocessing failure.", hipErrorTbd);
    }

    // Store finalized binary
    SrcMod->FinalizedBinary_ = std::move(Binary);

    return SrcMod;
}
```

---

## Module Compilation and Loading

### Lazy JIT Compilation

chipStar uses **lazy compilation**: SPIR-V modules are compiled to native code only when a kernel is first launched.

**Module Compilation Flow**:

```
User calls kernel<<<...>>>()
         │
         ▼
hipLaunchKernel()
         │
         ▼
Device::findKernel(hostPtr)
         │
         ▼
Device::getOrCreateModule(hostPtr)
         │
         ▼
Is module compiled? ──No──► CHIPModule::compile()
         │                          │
        Yes                         ▼
         │                  OpenCL: clCreateProgramWithIL()
         │                          │
         │                          ▼
         │                  clBuildProgram() [JIT compile]
         │                          │
         │                          ▼
         │                  Link runtime SPIR-V modules
         │                  (atomics, ballot, etc.)
         │                          │
         ▼◄─────────────────────────┘
Return Kernel object
```

### OpenCL Module Compilation

```cpp
// src/backend/OpenCL/CHIPBackendOpenCL.cc lines 1169-1220
void CHIPModuleOpenCL::compile(chipstar::Device *ChipDev) {
    logTrace("CHIPModuleOpenCL::compile()");
    auto start = std::chrono::high_resolution_clock::now();

    CHIPDeviceOpenCL *ChipDevOcl = (CHIPDeviceOpenCL *)ChipDev;
    CHIPContextOpenCL *ChipCtxOcl = (CHIPContextOpenCL *)(ChipDevOcl->getContext());

    // Get SPIR-V binary
    auto SrcBin = Src_->getBinary();

    // Build compiler flags
    std::string buildOptions =
        Backend->getDefaultJitFlags() + " " + ChipEnvVars.getJitFlags();
    // Default flags: "-cl-kernel-arg-info -cl-std=CL3.0"

    // Try loading from cache
    std::string cacheName = generateCacheName(SrcBin, deviceName);
    bool cached = load(*ChipCtxOcl->get(), {*ChipDevOcl->get()},
                       cacheName, Program_);

    if (!cached) {
        // Step 1: Compile main SPIR-V module
        cl::Program ClMainObj =
            compileIL(*ChipCtxOcl->get(), *ChipDevOcl,
                      SrcBin.data(), SrcBin.size(),
                      buildOptions.c_str());

        // Step 2: Add runtime device library modules (atomics, etc.)
        std::vector<cl::Program> ClObjects;
        ClObjects.push_back(ClMainObj);
        appendRuntimeObjects(*ChipCtxOcl->get(), *ChipDevOcl, ClObjects);

        // Step 3: Link all programs together
        Program_ = link(*ChipCtxOcl->get(), {*ChipDevOcl->get()}, ClObjects);

        // Step 4: Save to cache for future runs
        save(*ChipDevOcl->get(), Program_, cacheName);
    }

    auto end = std::chrono::high_resolution_clock::now();
    std::chrono::duration<double> elapsed = end - start;
    logInfo("Module compilation took {} seconds", elapsed.count());
}
```

### Compiling SPIR-V with OpenCL

```cpp
// Simplified from CHIPBackendOpenCL.cc
static cl::Program compileIL(cl::Context &Context,
                            CHIPDeviceOpenCL &ChipDev,
                            const void *IL, size_t Length,
                            const char *BuildOptions) {
    cl_int Err;

    // Create OpenCL program from SPIR-V IL
    cl::Program Prog(Context,
                    {*ChipDev.get()},      // Target device
                    IL,                     // SPIR-V binary
                    Length,                 // Binary size
                    &Err);

    CHIPERR_CHECK_LOG_AND_THROW_TABLE(clCreateProgramWithIL);

    // JIT compile the SPIR-V to native code
    Err = Prog.build(BuildOptions);

    if (Err != CL_SUCCESS) {
        // Get build log on failure
        std::string buildLog;
        Prog.getBuildInfo(*ChipDev.get(), CL_PROGRAM_BUILD_LOG, &buildLog);
        logError("OpenCL build failed:\n{}", buildLog);
        CHIPERR_LOG_AND_THROW("clBuildProgram failed", hipErrorTbd);
    }

    return Prog;
}
```

### Runtime Device Library Linking

chipStar links additional SPIR-V modules at runtime based on device capabilities:

```cpp
// Simplified pseudo-code
static void appendRuntimeObjects(cl::Context &Ctx,
                                CHIPDeviceOpenCL &Dev,
                                std::vector<cl::Program> &ClObjects) {
    // Check if device supports native float atomics
    if (Dev.hasExtension("cl_ext_float_atomics")) {
        // Link native atomic module
        auto NativeAtomics = compileEmbeddedSPIRV(
            Ctx, Dev,
            chipstar::rtdevlib::atomicAddFloat_native.data(),
            chipstar::rtdevlib::atomicAddFloat_native.size());
        ClObjects.push_back(NativeAtomics);
    } else {
        // Link emulated atomic module
        auto EmulatedAtomics = compileEmbeddedSPIRV(
            Ctx, Dev,
            chipstar::rtdevlib::atomicAddFloat_emulation.data(),
            chipstar::rtdevlib::atomicAddFloat_emulation.size());
        ClObjects.push_back(EmulatedAtomics);
    }

    // Similar for other runtime modules (ballot, etc.)
}
```

---

## Kernel Discovery and Registration

### Extracting Kernel Metadata from SPIR-V

chipStar analyzes the compiled program to discover kernel entry points and their signatures:

```cpp
// Simplified from CHIPModuleOpenCL.cc
void CHIPModuleOpenCL::consumeSPIRV(SPVModule *SrcMod) {
    SPVModuleInfo *ModInfo = SrcMod->getModuleInfo();

    // Iterate through all kernels found in SPIR-V
    for (auto &FuncInfoPair : ModInfo->FuncInfoMap) {
        std::string KernelName = FuncInfoPair.first;
        SPVFuncInfo *FuncInfo = FuncInfoPair.second.get();

        // Create OpenCL kernel handle
        cl_int Err;
        cl_kernel ClKern = clCreateKernel(Program_.get(),
                                          KernelName.c_str(),
                                          &Err);
        CHIPERR_CHECK_LOG_AND_THROW_TABLE(clCreateKernel);

        // Wrap in chipStar kernel object
        CHIPKernelOpenCL *ChipKernel = new CHIPKernelOpenCL(
            ClKern,
            KernelName,
            FuncInfo,
            (CHIPDeviceOpenCL *)ChipDev_);

        // Register kernel in module
        ChipKernels_.push_back(ChipKernel);
    }
}
```

### Kernel Argument Metadata

SPIR-V contains rich metadata about kernel arguments:

```cpp
// Represents a single kernel argument
struct KernelArg {
    unsigned Index;              // Argument position (0, 1, 2, ...)
    SPVTypeKind Kind;           // POD, Pointer, Image, Sampler, PODByRef
    size_t Size;                // Size in bytes
    const void *Data;           // Pointer to argument data
    SPVStorageClass SC;         // Address space for pointers

    bool isWorkgroupPtr() const {
        return Kind == SPVTypeKind::Pointer &&
               SC == SPVStorageClass::Workgroup;
    }
};

// Kernel function metadata
class SPVFuncInfo {
    std::string Name_;
    std::vector<KernelArg> Args_;
    size_t NumClientArgs_;     // Args visible to user (excludes dynamic shmem)
    bool HasByRefArgs_;        // True if any args are PODByRef

public:
    // Visitor pattern for processing arguments
    template <typename Visitor>
    void visitKernelArgs(void **ClientArgs, Visitor V) const {
        for (const auto &Arg : Args_) {
            KernelArg ArgCopy = Arg;
            if (Arg.Index < NumClientArgs_) {
                ArgCopy.Data = ClientArgs[Arg.Index];
            }
            V(ArgCopy);
        }
    }
};
```

---

## Kernel Argument Passing

### The ExecItem Abstraction

chipStar uses an **ExecItem** object to encapsulate a kernel launch request:

```cpp
// src/CHIPBackend.hh lines 1163-1282
class ExecItem {
protected:
    bool ArgsSetup = false;
    size_t SharedMem_;          // Dynamic shared memory size
    dim3 GridDim_;              // Grid dimensions
    dim3 BlockDim_;             // Block dimensions
    chipstar::Queue *ChipQueue_;
    void **Args_;               // Array of argument pointers

    std::shared_ptr<chipstar::ArgSpillBuffer> ArgSpillBuffer_;

public:
    void setArgs(void **Args) { Args_ = Args; }
    void setKernel(chipstar::Kernel *Kernel) = 0;

    // Sets up kernel arguments via backend API calls
    virtual void setupAllArgs() = 0;

    dim3 getGrid();
    dim3 getBlock();
    size_t getSharedMem();
    chipstar::Queue *getQueue();
};
```

### Argument Setup Process

The `setupAllArgs()` method marshals arguments to the backend:

```cpp
// src/backend/OpenCL/CHIPBackendOpenCL.cc lines 2036-2147
void CHIPExecItemOpenCL::setupAllArgs() {
    if (!ArgsSetup) {
        ArgsSetup = true;
    } else {
        return;  // Already setup
    }

    CHIPKernelOpenCL *Kernel = (CHIPKernelOpenCL *)getKernel();
    SPVFuncInfo *FuncInfo = Kernel->getFuncInfo();

    // Allocate spill buffer if needed for by-ref arguments
    if (FuncInfo->hasByRefArgs()) {
        ArgSpillBuffer_ =
            std::make_shared<chipstar::ArgSpillBuffer>(ChipQueue_->getContext());
        ArgSpillBuffer_->computeAndReserveSpace(*FuncInfo);
    }

    cl_kernel KernelHandle = ClKernel_.get()->get();

    // Lambda function to set each argument
    auto ArgVisitor = [&](const SPVFuncInfo::KernelArg &Arg) -> void {
        switch (Arg.Kind) {

        case SPVTypeKind::Image: {
            // Texture image argument
            auto *TexObj = *reinterpret_cast<const CHIPTextureOpenCL *const *>(Arg.Data);
            cl_mem Image = TexObj->getImage();
            Err = ::clSetKernelArg(KernelHandle, Arg.Index, sizeof(cl_mem), &Image);
            break;
        }

        case SPVTypeKind::Sampler: {
            // Texture sampler argument
            auto *TexObj = *reinterpret_cast<const CHIPTextureOpenCL *const *>(Arg.Data);
            cl_sampler Sampler = TexObj->getSampler();
            Err = ::clSetKernelArg(KernelHandle, Arg.Index, sizeof(cl_sampler), &Sampler);
            break;
        }

        case SPVTypeKind::POD: {
            // Plain old data (int, float, struct, etc.)
            logTrace("clSetKernelArg {} SIZE {} to {}", Arg.Index, Arg.Size, Arg.Data);
            Err = ::clSetKernelArg(KernelHandle, Arg.Index, Arg.Size, Arg.Data);
            break;
        }

        case SPVTypeKind::Pointer: {
            assert(Arg.Size == sizeof(void *));

            // Special case: dynamic shared memory (workgroup pointer)
            if (Arg.isWorkgroupPtr()) {
                logTrace("setLocalMemSize to {}", SharedMem_);
                Err = ::clSetKernelArg(KernelHandle, Arg.Index, SharedMem_, nullptr);
                break;
            }

            // Global/constant pointer
            auto *DevPtr = *reinterpret_cast<const void *const *>(Arg.Data);

            if (Ctx->getAllocStrategy() == AllocationStrategy::BufferDevAddr) {
                // Intel extension: cl_intel_unified_shared_memory
                Err = Ctx->clSetKernelArgDevicePointerEXT(KernelHandle, Arg.Index, DevPtr);
            } else {
                // Standard OpenCL SVM pointer
                Err = ::clSetKernelArgSVMPointer(KernelHandle, Arg.Index, DevPtr);
            }
            break;
        }

        case SPVTypeKind::PODByRef: {
            // Large POD passed by reference (spilled to device memory)
            auto *SpillSlot = ArgSpillBuffer_->allocate(Arg);
            Err = ::clSetKernelArgSVMPointer(KernelHandle, Arg.Index, SpillSlot);
            break;
        }

        }  // switch
    };

    // Visit all kernel arguments
    FuncInfo->visitKernelArgs(getArgs(), ArgVisitor);

    // Copy spill buffer to device if needed
    if (FuncInfo->hasByRefArgs()) {
        ChipQueue_->memCopyAsync(ArgSpillBuffer_->getDeviceBuffer(),
                                 ArgSpillBuffer_->getHostBuffer(),
                                 ArgSpillBuffer_->getSize(),
                                 hipMemcpyHostToDevice);
    }
}
```

### Argument Spill Buffer

For large arguments that must be passed by reference, chipStar uses a **spill buffer**:

```cpp
class ArgSpillBuffer {
    void *HostBuffer_;          // Host-side staging buffer
    void *DeviceBuffer_;        // Device-side buffer
    size_t Size_;
    size_t Offset_;

public:
    void computeAndReserveSpace(const SPVFuncInfo &FuncInfo) {
        Size_ = 0;
        // Calculate total space needed for by-ref args
        for (const auto &Arg : FuncInfo.getArgs()) {
            if (Arg.Kind == SPVTypeKind::PODByRef) {
                Size_ += roundUp(Arg.Size, 8);  // Align to 8 bytes
            }
        }

        // Allocate buffers
        HostBuffer_ = malloc(Size_);
        DeviceBuffer_ = Context->allocate(Size_, hipMemoryTypeDevice);
    }

    void *allocate(const SPVFuncInfo::KernelArg &Arg) {
        assert(Arg.Kind == SPVTypeKind::PODByRef);

        // Copy argument data to host buffer
        void *HostSlot = static_cast<char*>(HostBuffer_) + Offset_;
        memcpy(HostSlot, Arg.Data, Arg.Size);

        // Return corresponding device pointer
        void *DevSlot = static_cast<char*>(DeviceBuffer_) + Offset_;
        Offset_ += roundUp(Arg.Size, 8);

        return DevSlot;
    }
};
```

---

## Kernel Launch Pipeline

### High-Level Launch Flow

```
hipLaunchKernel(func, grid, block, args, sharedMem, stream)
         │
         ▼
1. Find kernel by host pointer
   Device::findKernel(func)
         │
         ▼
2. Create ExecItem
   Backend->createExecItem(grid, block, sharedMem, stream)
         │
         ▼
3. Set kernel and arguments
   ExecItem->setKernel(kernel)
   ExecItem->setArgs(args)
         │
         ▼
4. Marshal arguments to backend
   ExecItem->setupAllArgs()
         │
         ▼
5. Enqueue kernel
   Queue->launch(ExecItem)
         │
         ▼
6. Backend-specific submission
   [OpenCL: clEnqueueNDRangeKernel]
   [Level Zero: zeCommandListAppendLaunchKernel]
```

### hipLaunchKernel Implementation

```cpp
// Simplified from src/CHIPBindings.cc
hipError_t hipLaunchKernel(const void *HostFunction,
                          dim3 GridDim,
                          dim3 BlockDim,
                          void **Args,
                          size_t SharedMem,
                          hipStream_t Stream) {
    CHIP_TRY
    LOCK(ApiMtx);
    CHIPInitialize();

    // Step 1: Find the kernel associated with the host function pointer
    chipstar::Device *Device = Backend->getActiveDevice();
    chipstar::Kernel *Kernel = Device->findKernel(const_cast<void*>(HostFunction));

    if (!Kernel) {
        CHIPERR_LOG_AND_THROW("Kernel not found for host pointer",
                              hipErrorInvalidDeviceFunction);
    }

    // Step 2: Get the stream (queue)
    chipstar::Queue *Queue = Stream ? Stream : Device->getDefaultQueue();

    // Step 3: Create execution item
    chipstar::ExecItem *ExecItem = Backend->createExecItem(
        GridDim, BlockDim, SharedMem, Queue);

    ExecItem->setKernel(Kernel);
    ExecItem->setArgs(Args);

    // Step 4: Setup arguments
    ExecItem->setupAllArgs();

    // Step 5: Launch!
    Queue->launch(ExecItem);

    // Step 6: Cleanup
    delete ExecItem;

    CHIP_CATCH
    return hipSuccess;
}
```

---

## Backend-Specific Execution (OpenCL)

### Queue::launch() Implementation

```cpp
// src/backend/OpenCL/CHIPBackendOpenCL.cc
void CHIPQueueOpenCL::launch(chipstar::ExecItem *ExecItem) {
    CHIPExecItemOpenCL *ExecItemOcl = (CHIPExecItemOpenCL *)ExecItem;
    CHIPKernelOpenCL *Kernel = ExecItemOcl->getKernel();

    dim3 Grid = ExecItem->getGrid();
    dim3 Block = ExecItem->getBlock();

    // Calculate global work size and local work size
    size_t GlobalWorkSize[3] = {
        Grid.x * Block.x,
        Grid.y * Block.y,
        Grid.z * Block.z
    };

    size_t LocalWorkSize[3] = {
        Block.x,
        Block.y,
        Block.z
    };

    // Enqueue kernel execution
    cl_int Err = clEnqueueNDRangeKernel(
        Queue_,                          // Command queue
        Kernel->getHandle(),             // Kernel handle
        3,                               // Work dimensions (always 3 for HIP)
        nullptr,                         // Global work offset (always NULL)
        GlobalWorkSize,                  // Global work size
        LocalWorkSize,                   // Local work size (block size)
        0,                               // Num events in wait list
        nullptr,                         // Event wait list
        &ClEvent);                       // Event for this kernel

    CHIPERR_CHECK_LOG_AND_THROW_TABLE(clEnqueueNDRangeKernel);

    // Wrap OpenCL event in chipStar event
    chipstar::Event *Event = new CHIPEventOpenCL(this, ClEvent);
    EventMonitor_->registerEvent(Event);
}
```

### OpenCL Kernel Execution

Once `clEnqueueNDRangeKernel` is called:

1. **OpenCL Runtime** enqueues the kernel on the device
2. **Driver** schedules the kernel for execution
3. **Hardware** executes work-groups in parallel
4. **Event** signals completion when all work-groups finish

```
clEnqueueNDRangeKernel
         │
         ▼
┌────────────────────────────────────────┐
│     OpenCL Runtime (Host CPU)          │
│  - Command queue management            │
│  - Argument validation                 │
│  - Work-group scheduling               │
└────────┬───────────────────────────────┘
         │
         ▼
┌────────────────────────────────────────┐
│     OpenCL Driver                      │
│  - Translate to hardware commands      │
│  - Memory synchronization              │
│  - Submit to GPU                       │
└────────┬───────────────────────────────┘
         │
         ▼
┌────────────────────────────────────────┐
│     GPU Hardware                       │
│  - Execute work-groups in parallel     │
│  - Read arguments from memory          │
│  - Write results back                  │
└────────┬───────────────────────────────┘
         │
         ▼
     Event signals completion
```

---

## Complete Execution Flow Example

Let's trace a complete kernel execution from source to hardware:

### User Code

```cpp
// kernel.hip
#include <hip/hip_runtime.h>

__global__ void vectorAdd(float* a, float* b, float* c, int n) {
    int tid = threadIdx.x + blockIdx.x * blockDim.x;
    if (tid < n) {
        c[tid] = a[tid] + b[tid];
    }
}

int main() {
    const int N = 1024;

    // Allocate device memory
    float *d_a, *d_b, *d_c;
    hipMalloc(&d_a, N * sizeof(float));
    hipMalloc(&d_b, N * sizeof(float));
    hipMalloc(&d_c, N * sizeof(float));

    // ... initialize d_a and d_b ...

    // Launch kernel
    dim3 grid(4);    // 4 blocks
    dim3 block(256); // 256 threads per block
    vectorAdd<<<grid, block>>>(d_a, d_b, d_c, N);

    hipDeviceSynchronize();

    // ... use results ...

    return 0;
}
```

### Compilation Phase

```bash
# Compile with hipcc
hipcc kernel.hip -o kernel

# What happens:
# 1. Clang compiles device code to SPIR-V
# 2. SPIR-V embedded in .hip_fatbin ELF section
# 3. Clang generates registration code:
#    - __hipRegisterFatBinary(&__hip_fatbin_data)
#    - __hipRegisterFunction(handle, &vectorAdd, "_Z9vectorAddPfS_S_i")
# 4. Host code compiled to x86-64
# 5. Linked into single executable
```

### Program Startup

```cpp
// Before main() executes:

// 1. C++ global constructors run
__attribute__((constructor))
void __hip_module_register() {
    // Extract SPIR-V from .hip_fatbin section
    void *fatbin = &__hip_fatbin_data;
    std::string_view spirv = extractSPIRVModule(fatbin);

    // Register SPIR-V module
    SPVRegister::Handle handle = SPVRegister::get().registerSource(spirv);

    // Register vectorAdd function
    SPVRegister::get().bindFunction(handle, &vectorAdd, "_Z9vectorAddPfS_S_i");
}

// 2. Now main() begins execution
```

### Kernel Launch

```cpp
// When vectorAdd<<<grid, block>>>(...) executes:

// 1. Compiler-generated stub calls:
hipLaunchKernel((const void*)&vectorAdd,
                dim3(4, 1, 1),      // grid
                dim3(256, 1, 1),    // block
                args,               // {&d_a, &d_b, &d_c, &N}
                0,                  // shared memory
                nullptr);           // default stream

// 2. Inside hipLaunchKernel:

// Find kernel by host pointer
chipstar::Kernel *kernel = Device->findKernel(&vectorAdd);

// First time? Compile the module
if (!kernel) {
    // Get SPIR-V module
    SPVModule *spvMod = SPVRegister::get().getSource(&vectorAdd);

    // JIT compile with OpenCL
    CHIPModule *module = new CHIPModuleOpenCL(spvMod);
    module->compile(Device);  // clCreateProgramWithIL + clBuildProgram

    // Extract kernel
    kernel = module->getKernelByName("_Z9vectorAddPfS_S_i");
}

// Create execution item
CHIPExecItemOpenCL *execItem = new CHIPExecItemOpenCL(
    dim3(4, 1, 1),      // grid
    dim3(256, 1, 1),    // block
    0,                  // shared mem
    defaultQueue);

execItem->setKernel(kernel);
execItem->setArgs(args);

// 3. Setup arguments
execItem->setupAllArgs();
//   - Arg 0: clSetKernelArgSVMPointer(kernel, 0, d_a)
//   - Arg 1: clSetKernelArgSVMPointer(kernel, 1, d_b)
//   - Arg 2: clSetKernelArgSVMPointer(kernel, 2, d_c)
//   - Arg 3: clSetKernelArg(kernel, 3, sizeof(int), &N)

// 4. Launch!
defaultQueue->launch(execItem);
//   size_t global[3] = {1024, 1, 1};  // 4 blocks × 256 threads
//   size_t local[3] = {256, 1, 1};    // Block size
//   clEnqueueNDRangeKernel(queue, kernel, 3, nullptr, global, local, ...);
```

### GPU Execution

```
OpenCL Driver receives kernel launch
         │
         ▼
Allocates 4 work-groups (blocks)
         │
         ▼
┌────────────────────────────────────────┐
│  Work-group 0          Work-group 1   │
│  blockIdx.x = 0        blockIdx.x = 1  │
│  Threads 0-255         Threads 256-511 │
│                                        │
│  Work-group 2          Work-group 3   │
│  blockIdx.x = 2        blockIdx.x = 3  │
│  Threads 512-767       Threads 768-1023│
└────────────────────────────────────────┘
         │
         ▼
Each thread executes:
  int tid = threadIdx.x + blockIdx.x * 256;
  if (tid < 1024) {
      c[tid] = a[tid] + b[tid];
  }
         │
         ▼
All work-groups complete
         │
         ▼
Event signals completion
```

### Synchronization

```cpp
// hipDeviceSynchronize() waits for completion
hipDeviceSynchronize();
//   → defaultQueue->finish()
//   → clFinish(clQueue)
//   → Blocks until all queued kernels complete
```

---

## Summary

The chipStar runtime architecture demonstrates a sophisticated multi-layer design:

1. **Compiler Integration**: Clang embeds SPIR-V in ELF sections and generates registration code
2. **Fat Binary Extraction**: Runtime extracts device code from bundled format
3. **Global Registry**: `SPVRegister` maps host pointers to SPIR-V modules and symbols
4. **Lazy Compilation**: Modules compiled on-demand via OpenCL/Level Zero JIT
5. **Metadata-Driven Execution**: SPIR-V analysis provides type-safe argument marshalling
6. **Backend Abstraction**: Common interfaces support multiple execution engines

**Performance Optimizations**:
- **Module Caching**: Compiled binaries cached to disk for faster subsequent runs
- **Lazy Loading**: Kernels compiled only when used
- **Argument Spilling**: Large arguments efficiently passed via device memory
- **Runtime Linking**: Capability-dependent code linked at JIT time

**Key File References**:
- `tools/spirv-extractor/spirv-extractor.hh` - Fat binary extraction (lines 34-218)
- `src/SPVRegister.cc` - Module registration (lines 47-210)
- `src/backend/OpenCL/CHIPBackendOpenCL.cc` - Module compilation (lines 1169-1220)
- `src/backend/OpenCL/CHIPBackendOpenCL.cc` - Argument setup (lines 2036-2147)
- `src/CHIPBackend.hh` - ExecItem abstraction (lines 1163-1282)

---

**Document Version**: 1.0
**Date**: 2025-10-22
**chipStar Version**: Based on current main branch
**Author**: Analysis of chipStar runtime codebase
